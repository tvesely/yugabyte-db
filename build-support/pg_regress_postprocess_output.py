#!/usr/bin/env python

"""
Filters the given file in place, removing blocks like the following that are generated by ASAN/TSAN:

-----------------------------------------------------
Suppressions used:
  count      bytes template
      1        552 save_ps_display_args
-----------------------------------------------------

"""

import sys
import os
import re

SANITIZER_SEPARATOR_LINE = '-' * 53


def main():
    file_path = sys.argv[1]

    if not os.path.exists(file_path):
        # Auto-create files of this form: .../regress/expected/yb_char.out
        # This is convenient so we can still get sane results when adding new tests.
        if os.path.dirname(file_path).endswith('/regress/expected'):
            with open(file_path, 'w') as output_file:
                output_file.write(
                    '-- Automatically created by %s (new test?)\n' % os.path.basename(__file__))

    lines = []
    with open(file_path) as input_file:
        lines = input_file.readlines()

    # 1) Remove trailing whitespace. We will also do that to expected output files so that diff does
    #    not find any differences in the normal case.
    # 2) Also mask any uuids since they are randomly generated and will vary across runs.
    lines = [line.rstrip() for line in lines]

    mask_uuid4s = r"([0-9A-Fa-f]{8})-([0-9A-Fa-f]{4})-4([0-9A-Fa-f]{3})-([89ABab][0-9A-Fa-f]{3})-([0-9A-Fa-f]{12})"
    mask_transaction_timestamps = r"Value write after transaction start:\s+{ days:\s+(\d+)\s+time:\s+(\d+):(\d+):(\d+).(\d+) } >= { days:\s+(\d+)\s+time:\s+(\d+):(\d+):(\d+).(\d+) }.*kConflict"

    def mask_groups(match):
        chars = list(match.string)
        for i, _ in enumerate(match.groups()):
            start, end = match.span(i+1)
            for j in range(start,end):
                chars[j] = "*"
        start, end = match.span(0)
        return "".join(chars[start:end])

    # Mask out anything in a regex match group
    def mask_lines(lines, *regex_list):
        masked_lines = []
        for line in lines:
            for regex in regex_list:
                line = re.sub(regex, mask_groups, line)
            masked_lines.append(line)
        return masked_lines

    lines = mask_lines(lines, mask_uuid4s, mask_transaction_timestamps)

    result_lines = []
    i = 0
    skipping = False
    just_stopped_skipping = False
    while i < len(lines):
        if lines[i] == '-- YB_DATA_END':
            # Line indicates end of data. All further statements designed for maintenance
            # and must be removed from in result output.
            break

        just_started_skipping = False
        if (lines[i] == SANITIZER_SEPARATOR_LINE and
                i + 1 < len(lines) and
                lines[i + 1] == 'Suppressions used:'):
            skipping = True
            just_started_skipping = True

        if not skipping and not (
            # We skip one more empty line after the closing horizontal line of a suppressions block.
            just_stopped_skipping and not lines[i].strip()
        ):
            result_lines.append(lines[i])

        just_stopped_skipping = False

        if (skipping and
                lines[i] == SANITIZER_SEPARATOR_LINE and
                not just_started_skipping):
            skipping = False
            just_stopped_skipping = True
        i += 1

    # Remove empty lines from the end of the file.
    new_len = len(result_lines)
    while new_len > 0 and result_lines[new_len - 1].strip() == '':
        new_len -= 1
    if new_len < len(result_lines):
        result_lines = result_lines[:new_len]

    with open(file_path, 'w') as output_file:
        output_file.write("\n".join(result_lines) + "\n")


if __name__ == '__main__':
    main()
